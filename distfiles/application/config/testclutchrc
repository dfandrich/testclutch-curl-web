# Testclutch configuration file

# Code repository to work on
check_repo = 'https://github.com/curl/curl'

# log parsing functions to try, in order
log_parsers = [
    'testclutch.logparser.curlparse.parse_log_file',
    'testclutch.logparser.pytestparse.parse_log_file',
    'testclutch.logparser.pytestparse.parse_log_file_summary',
]

# Whether to stop searching for more log files after the first one is found
log_parse_single = False

# Maximum number of builds to look at when performing flaky analysis
# curl does around 100 per month, so 300 means about 3 months worth of tests
flaky_builds_max = 300

# Time in hours that makes a job "disabled"
disabled_job_hours = 24 * 6  # 6 days

# Report configuration: test_results_count
# Number of failed tests for which to bother showing URLs (since that is slow)
test_results_count_max_urls = 110

# Which origins need to be checked before commenting on a PR
pr_comment_origins = frozenset(('circle', 'gha'))

# URL to use for Test Clutch in PR comments
pr_comment_url = 'https://testclutch.curl.se/'
#
# Regexes of metadata fields whose values are NOT dumped in the metadata_values report
metadata_stats_ignored = [r'(^host|^jobid|^runid|^runurl|^systemhost|^url|^workflowid|duration|time)$', r'^curl.*size$']

# Metadata fields over which to create the features matrix
matrix_meta_fields = ['mintests', 'arch', 'targetarch', 'os', 'systemosver', 'buildsystem',
                      'compiler', 'compilerversion', 'testformat', 'testmode', 'withvalgrind',
                      'withevent', 'withduphandle', 'paralleljobs', 'dailybuild', 'curldeps',
                      'features', 'curlprotocols']

# Metadata fields to split into subfields using a regular expression
# The format is {'fieldname': r'<regex>', ...}  where <regex> is passed to re.split to split a text
# string into multiple values, each of which is treated like a separate feature value.
matrix_meta_splits = {
    'curldeps': r'(?:/[^ ]+(?: |$))|(?: )',
    'curlprotocols': r' ',
    'features': r' ',
}

# Transformations to perform on the metadata fields in matrix_meta_fields
# The format is {'fieldname': [('pattern1', 'replacement2'), ('pattern2', 'replacement2'), ...]
# where the pattern and replacement strings are as specified for re.sub(). They are executed in
# the order given for each fieldname and on each value resulting from matrix_meta_splits.
matrix_meta_transforms = {
    'arch': [('(?i)^arm64$', 'aarch64'), (r'(?i)^amd64$', 'x86_64')],
    'compiler': [(r'^(GNU|GNU_C)$', 'gcc'), (r'(?i)^clang$', 'clang'),
                 (r'^INTEL_UNIX_C$', 'IntelC'), (r'^TINY_C$', 'TinyC'),
                 (r'(?i)^APPLECLANG$', 'AppleClang'), (r'^SUNPRO_C$', 'SunProC')],
    'curldeps': [(r'\(', ''), (r'^libcurl$', '')],  # parenthesized dependencies & useless libcurl
    'dailybuild': [(r'^\d+$', 'yes')],
    'targetarch': [('(?i)^arm64$', 'aarch64'), (r'(?i)^amd64$', 'x86_64')],
    'withduphandle': [(r'^no$', '')],  # leave only 'yes'
    'withevent': [(r'^no$', '')],     # leave only 'yes'
    'withvalgrind': [(r'^no$', '')],  # leave only 'yes'
    'testmode': [(r'^normal$', '')],  # leave only 'torture'
}

# Metadata fields whose value to simply display after transformation
matrix_meta_dump = frozenset({
    'compilerversion',
    'mintests',
    'paralleljobs',
    'systemosver'
})

# Whether to look at only the last result of a test as its result if more than one result is found
# in a run.  This should be done if failing tests are automatically rerun in case of flakiness.
rerun_tests = True
