#!/bin/bash
# Daily job to download logs and generate reports
set -o pipefail
. "$(dirname "$0")"/setup-vars

# Number of hours of logs to bring in on every run
# This must be larger than the time between cron runs to avoid missing logs,
# and ideally more than the time between two runs in case one is skipped.
readonly HOURS=16

# Number of hours for statistics jobs that take too much memory to run for
# the full 90 days
readonly REDUCEDSTATSHOURS=$((30 * 24))

# Minimum disk space needed (in KiB)
readonly MINSPACE=200000

# Log lines (may) begin with <level>
readonly LOGCMD='systemd-cat --level-prefix=true --priority=warning'
# Log lines do not begin with <level>
readonly LOGCMDNOLVL='systemd-cat --level-prefix=false --priority=warning'
# First argument is an identifier; this is used in a pipe where the command can't be identified
readonly LOGCMDID='systemd-cat --level-prefix=true --priority=warning --identifier'
# Log a high-priority failure message
readonly LOGFAILURE='eval systemd-cat --level-prefix=false --priority=err echo Job failed with status $?'

# $LOGCMD prefix for the error level
readonly ERRLVL='<3>'

# Enable syslog prefixes on logs, and optionally the verbosity level
#readonly VERBOSITY=--debug --level-prefix
readonly VERBOSITY="--verbose --level-prefix"

# Enable dry-run mode on those programs that offer it
#readonly DRY=--dry-run
readonly DRY=

# Directory holding public summary reports
readonly REPORTROOT="$HOME/ROOT/static/reports"

# First commit in DB
readonly FIRST_COMMIT=ff67da58c4add27b05d237533d1cb39fb3894113

$LOGCMDNOLVL echo Starting daily update
$LOGCMDNOLVL echo "version $(cat "$HOME/ROOT/version.txt")"

# Check for adequate disk space before starting
if [[ "$(df --output=avail -k "$XDG_DATA_HOME" | tail -1)" -lt "$MINSPACE" ]]; then
    $LOGCMDNOLVL echo "Not enough disk space available"
    $LOGCMDNOLVL df
    $LOGCMD echo "${ERRLVL}Aborted daily update"
    exit 1
fi

# Look for an old job still running.
# It's really slow if it is, but give it a chance to finish.
readonly LOCKFILE="$XDG_RUNTIME_DIR"/tc-update.lock

if [[ -e "$LOCKFILE" ]]; then
    $LOGCMDNOLVL echo "Update lock already exists (PID $(cat "$LOCKFILE"))"
    $LOGCMDNOLVL echo -n Lock created:
    $LOGCMDNOLVL ls -l "$LOCKFILE"
    if ps -p "$(cat "$LOCKFILE")" > /dev/null; then
        $LOGCMD echo "${ERRLVL}Aborted daily update"
        exit 1
    fi
    $LOGCMDNOLVL echo Deleting stale lock
    # No need to actually delete anything; the lock will be overwritten instead.
    # Note that there is still a brief race condition here, but it shouldn't cause any issue in
    # reality because this script is run (and the lock checked) only every few hours.
fi
echo $$ > "$LOCKFILE"

# Download logs
$LOGCMD tcingestlog $VERBOSITY $DRY --origin=circle --howrecent $HOURS || $LOGFAILURE
$LOGCMD tcingestlog $VERBOSITY $DRY --origin=curlauto --howrecent $HOURS || $LOGFAILURE
if [[ -r "$XDG_DATA_HOME/auth/ghatoken" ]]; then
    $LOGCMD tcingestlog $VERBOSITY $DRY --origin=gha --authfile "$XDG_DATA_HOME/auth/ghatoken" --howrecent $HOURS || $LOGFAILURE
else
    $LOGCMD echo "${ERRLVL}Skipping GHA ingestion due to no available token"
fi

# Update the git checkout
# git 1.8.3 doesn't support -C to select the repository to use
$LOGCMDNOLVL env GIT_DIR="$XDG_DATA_HOME/curl.git" git fetch origin master:master || $LOGFAILURE
# Since this is done entirely locally, always ingest a lot more than we need to to reduce
# the chance of a commit being missed.
readonly GITHOURS=$((HOURS * 50))
$LOGCMD tcgitcommitinfo $VERBOSITY $DRY "$XDG_DATA_HOME/curl.git" "$GITHOURS hours ago" || $LOGFAILURE
# If this shows an error, use commitchainrev to start at the given commit and use the last
# "commit" in the list as the last parameter in this command:
if ! $LOGCMDNOLVL tcdbutil checkcommitchain https://github.com/curl/curl master "$FIRST_COMMIT"; then
    tcdbutil commitchainrev https://github.com/curl/curl master | tail -8 | $LOGCMDID tcdbutil
    $LOGCMD echo "${ERRLVL}checkcommitchain failure"
fi

# Replace short hashes with long ones
$LOGCMD tcaugmentgithash $VERBOSITY $DRY || $LOGFAILURE

if [[ "$1" == "--no-reports" ]]; then

    $LOGCMDNOLVL echo Skipping report generation

else
    # Generate reports
    $LOGCMDNOLVL echo Starting report generation

    REPORTTMP="$(mktemp "$REPORTROOT/tmp.XXXXXXXXXX")"
    tcmetadatastats $VERBOSITY --html --report=metadata_values 2>&1 > "$REPORTTMP" | $LOGCMDID tcmetadatastats || $LOGFAILURE
    mv "$REPORTTMP" "$REPORTROOT"/metadata-summary.html

    REPORTTMP="$(mktemp "$REPORTROOT/tmp.XXXXXXXXXX")"
    tcmetadatastats $VERBOSITY --html --report=feature_matrix 2>&1 > "$REPORTTMP" | $LOGCMDID tcmetadatastats || $LOGFAILURE
    mv "$REPORTTMP" "$REPORTROOT"/feature-matrix.html

    REPORTTMP="$(mktemp "$REPORTROOT/tmp.XXXXXXXXXX")"
    tcmetadatastats $VERBOSITY --html --report=test_run_stats --howrecent="$REDUCEDSTATSHOURS" 2>&1 > "$REPORTTMP" | $LOGCMDID tcmetadatastats || $LOGFAILURE
    mv "$REPORTTMP" "$REPORTROOT"/test-stats.html

    REPORTTMP="$(mktemp "$REPORTROOT/tmp.XXXXXXXXXX")"
    tcmetadatastats $VERBOSITY --html --report=test_results_count --howrecent="$REDUCEDSTATSHOURS" 2>&1 > "$REPORTTMP" | $LOGCMDID tcmetadatastats || $LOGFAILURE
    mv "$REPORTTMP" "$REPORTROOT"/results-count.html

    REPORTTMP="$(mktemp "$REPORTROOT/tmp.XXXXXXXXXX")"
    tcanalysissum $VERBOSITY --html 2>&1 > "$REPORTTMP" | $LOGCMDID tcanalysissum || $LOGFAILURE
    mv "$REPORTTMP" "$REPORTROOT"/summary.html

fi

# Delete run lock file at end
rm -f "$LOCKFILE"

$LOGCMDNOLVL echo Completed daily update
